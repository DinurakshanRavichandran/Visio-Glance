{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DinurakshanRavichandran/Visio-Glance/blob/Fundus-eye-disease-detection/custom_one.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3QhH2jwALohe",
        "outputId": "845593ab-82af-4f7d-9aa7-c20157d9ca0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 3384 images belonging to 4 classes.\n",
            "Found 844 images belonging to 4 classes.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node compile_loss/weighted_categorical_crossentropy/mul defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/ioloop.py\", line 699, in <lambda>\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/ioloop.py\", line 750, in _run_callback\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 824, in inner\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 785, in run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 233, in wrapper\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 233, in wrapper\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 233, in wrapper\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-2-d97f38cfa623>\", line 153, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 60, in train_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/trainer.py\", line 383, in _compute_loss\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/trainer.py\", line 351, in compute_loss\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py\", line 691, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py\", line 700, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/losses/loss.py\", line 67, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py\", line 33, in call\n\n  File \"<ipython-input-2-d97f38cfa623>\", line 128, in weighted_categorical_crossentropy\n\nIncompatible shapes: [4] vs. [32]\n\t [[{{node compile_loss/weighted_categorical_crossentropy/mul}}]] [Op:__inference_multi_step_on_iterator_18399]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d97f38cfa623>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;31m# ================== Training ==================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0mtrain_dual_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/weighted_categorical_crossentropy/mul defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/ioloop.py\", line 699, in <lambda>\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/ioloop.py\", line 750, in _run_callback\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 824, in inner\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 785, in run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 233, in wrapper\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 233, in wrapper\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/gen.py\", line 233, in wrapper\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-2-d97f38cfa623>\", line 153, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 60, in train_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/trainer.py\", line 383, in _compute_loss\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/trainer.py\", line 351, in compute_loss\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py\", line 691, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py\", line 700, in call\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/losses/loss.py\", line 67, in __call__\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py\", line 33, in call\n\n  File \"<ipython-input-2-d97f38cfa623>\", line 128, in weighted_categorical_crossentropy\n\nIncompatible shapes: [4] vs. [32]\n\t [[{{node compile_loss/weighted_categorical_crossentropy/mul}}]] [Op:__inference_multi_step_on_iterator_18399]"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = 224\n",
        "CATEGORIES = ['cataract', 'diabetic_retinopathy', 'glaucoma', 'normal']\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50  # Increased to allow for early stopping\n",
        "DATA_DIR = '/content/drive/MyDrive/data set/dataset'\n",
        "\n",
        "# ================== Enhanced Data Augmentation ==================\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    channel_shift_range=50,\n",
        "    fill_mode='constant',\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Train generator with explicit class order\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=CATEGORIES  # Critical fix for label alignment\n",
        ")\n",
        "\n",
        "# Validation generator\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    classes=CATEGORIES  # Critical fix for label alignment\n",
        ")\n",
        "\n",
        "# ================== Class Weight Calculation ==================\n",
        "y_train = train_generator.classes\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(CATEGORIES))}\n",
        "\n",
        "# ================== Dual Input Generator ==================\n",
        "def dual_input_generator(generator):\n",
        "    for x, y in generator:\n",
        "        yield ((x, x), y)  # Dual input format\n",
        "\n",
        "train_dual_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: dual_input_generator(train_generator),\n",
        "    output_signature=(\n",
        "        (tf.TensorSpec(shape=(None, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32),\n",
        "         tf.TensorSpec(shape=(None, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32)),\n",
        "        tf.TensorSpec(shape=(None, len(CATEGORIES)), dtype=tf.float32)\n",
        "    )\n",
        ").prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_dual_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: dual_input_generator(val_generator),\n",
        "    output_signature=(\n",
        "        (tf.TensorSpec(shape=(None, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32),\n",
        "         tf.TensorSpec(shape=(None, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32)),\n",
        "        tf.TensorSpec(shape=(None, len(CATEGORIES)), dtype=tf.float32)\n",
        "    )\n",
        ").prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# ================== Enhanced Model Architecture ==================\n",
        "def create_model():\n",
        "    # Base models\n",
        "    vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "    # Freeze initial layers\n",
        "    for layer in vgg_base.layers:\n",
        "        layer.trainable = False\n",
        "    for layer in resnet_base.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Optional: Unfreeze last few layers for fine-tuning\n",
        "    # for layer in vgg_base.layers[-8:]:\n",
        "    #     layer.trainable = True\n",
        "    # for layer in resnet_base.layers[-8:]:\n",
        "    #     layer.trainable = True\n",
        "\n",
        "    # Feature extraction\n",
        "    vgg_gap = GlobalAveragePooling2D()(vgg_base.output)\n",
        "    resnet_gap = GlobalAveragePooling2D()(resnet_base.output)\n",
        "    merged = tf.keras.layers.concatenate([vgg_gap, resnet_gap])\n",
        "\n",
        "    # Enhanced classifier with regularization\n",
        "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(merged)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.7)(x)\n",
        "    outputs = Dense(len(CATEGORIES), activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=[vgg_base.input, resnet_base.input], outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "# ================== Custom Loss with Class Weights ==================\n",
        "def weighted_categorical_crossentropy(y_true, y_pred):\n",
        "    weights = tf.constant(list(class_weight_dict.values()), dtype=tf.float32)\n",
        "    weighted_loss = tf.reduce_mean(weights * tf.keras.losses.categorical_crossentropy(y_true, y_pred))\n",
        "    return weighted_loss\n",
        "\n",
        "# ================== Model Compilation ==================\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=weighted_categorical_crossentropy,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# ================== Callbacks ==================\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss', factor=0.2, patience=5, verbose=1, min_lr=1e-7\n",
        "    ),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=10, restore_best_weights=True, verbose=1\n",
        "    ),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        '/content/best_model.h5', save_best_only=True, monitor='val_accuracy'\n",
        "    )\n",
        "]\n",
        "\n",
        "# ================== Training ==================\n",
        "history = model.fit(\n",
        "    train_dual_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_dual_dataset,\n",
        "    callbacks=callbacks,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_steps=len(val_generator),\n",
        "    class_weight=class_weight_dict\n",
        ")\n",
        "\n",
        "# ================== Proper Evaluation ==================\n",
        "# Get true labels\n",
        "y_true = val_generator.classes\n",
        "\n",
        "# Predict with proper length handling\n",
        "y_pred_probs = model.predict(val_dual_dataset, steps=len(val_generator))\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)[:len(y_true)]  # Trim to match exact validation size\n",
        "\n",
        "# Calculate metrics\n",
        "val_accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"\\nFinal Validation Accuracy: {val_accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=CATEGORIES))\n",
        "\n",
        "# ================== Optional: Fine-Tuning ==================\n",
        "# Uncomment to continue training with unfrozen layers\n",
        "# for layer in model.layers:\n",
        "#     if 'vgg16' in layer.name or 'resnet50' in layer.name:\n",
        "#         layer.trainable = True\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=Adam(learning_rate=1e-6),\n",
        "#     loss=weighted_categorical_crossentropy,\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "# history_fine = model.fit(\n",
        "#     train_dual_dataset,\n",
        "#     epochs=5,\n",
        "#     validation_data=val_dual_dataset,\n",
        "#     initial_epoch=history.epoch[-1],\n",
        "#     callbacks=callbacks\n",
        "# )\n",
        "\n",
        "# Save final model\n",
        "model.save('/content/retinal_disease_model_v2.keras')\n",
        "print(\"Model saved successfully.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNm1rIYFmt9bgGhlx78Nud/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}