{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DinurakshanRavichandran/Visio-Glance/blob/Fundus-eye-disease-detection/Fixed_Custom_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QhH2jwALohe",
        "outputId": "38feaf4f-706c-4a3c-89cc-96867738a0f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found 3384 images belonging to 4 classes.\n",
            "Found 844 images belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m783s\u001b[0m 7s/step - accuracy: 0.6806 - loss: 0.8691 - val_accuracy: 0.6848 - val_loss: 1.0449 - learning_rate: 0.0010\n",
            "Epoch 2/25\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 888ms/step - accuracy: 0.8129 - loss: 0.4899 - val_accuracy: 0.7133 - val_loss: 0.7916 - learning_rate: 0.0010\n",
            "Epoch 3/25\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 882ms/step - accuracy: 0.8463 - loss: 0.4316 - val_accuracy: 0.7346 - val_loss: 0.7363 - learning_rate: 0.0010\n",
            "Epoch 4/25\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 880ms/step - accuracy: 0.8636 - loss: 0.3803 - val_accuracy: 0.7761 - val_loss: 0.5555 - learning_rate: 0.0010\n",
            "Epoch 5/25\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 876ms/step - accuracy: 0.8612 - loss: 0.3592 - val_accuracy: 0.6588 - val_loss: 1.0044 - learning_rate: 0.0010\n",
            "Epoch 6/25\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 879ms/step - accuracy: 0.8787 - loss: 0.3333 - val_accuracy: 0.7346 - val_loss: 0.7144 - learning_rate: 0.0010\n",
            "Epoch 7/25\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 887ms/step - accuracy: 0.8738 - loss: 0.3293 - val_accuracy: 0.7737 - val_loss: 0.5721 - learning_rate: 0.0010\n",
            "Epoch 8/25\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 884ms/step - accuracy: 0.8853 - loss: 0.3012 - val_accuracy: 0.7251 - val_loss: 0.7574 - learning_rate: 0.0010\n",
            "Epoch 9/25\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739ms/step - accuracy: 0.8998 - loss: 0.2554\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 884ms/step - accuracy: 0.8997 - loss: 0.2557 - val_accuracy: 0.7429 - val_loss: 0.7110 - learning_rate: 0.0010\n",
            "Epoch 10/25\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 879ms/step - accuracy: 0.8937 - loss: 0.2919 - val_accuracy: 0.7310 - val_loss: 0.6397 - learning_rate: 1.0000e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 877ms/step - accuracy: 0.9112 - loss: 0.2454 - val_accuracy: 0.7476 - val_loss: 0.6214 - learning_rate: 1.0000e-04\n",
            "Epoch 12/25\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 872ms/step - accuracy: 0.9088 - loss: 0.2487 - val_accuracy: 0.7393 - val_loss: 0.6469 - learning_rate: 1.0000e-04\n",
            "Epoch 13/25\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 874ms/step - accuracy: 0.9122 - loss: 0.2378 - val_accuracy: 0.7370 - val_loss: 0.6421 - learning_rate: 1.0000e-04\n",
            "Epoch 14/25\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734ms/step - accuracy: 0.9165 - loss: 0.2297\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 877ms/step - accuracy: 0.9166 - loss: 0.2295 - val_accuracy: 0.7393 - val_loss: 0.6213 - learning_rate: 1.0000e-04\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 556ms/step - accuracy: 0.7483 - loss: 0.5834\n",
            "Validation Accuracy: 0.7713\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 681ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Validation Set: 0.2666\n",
            "Model saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = 224\n",
        "CATEGORIES = ['cataract', 'diabetic_retinopathy', 'glaucoma', 'normal']\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25\n",
        "DATA_DIR = '/content/drive/MyDrive/data set/dataset'\n",
        "\n",
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    DATA_DIR, target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical', subset='training'\n",
        ")\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    DATA_DIR, target_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical', subset='validation'\n",
        ")\n",
        "\n",
        "# Compute class weights\n",
        "y_train = train_generator.classes\n",
        "class_weights_dict = dict(enumerate(compute_class_weight(\n",
        "    class_weight='balanced', classes=np.unique(y_train), y=y_train\n",
        ")))\n",
        "\n",
        "# Load pre-trained ResNet50\n",
        "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "# Freeze early layers\n",
        "for layer in resnet_base.layers[:-5]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Feature extraction\n",
        "x = GlobalAveragePooling2D()(resnet_base.output)\n",
        "x = Dense(256)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(len(CATEGORIES), activation='softmax')(x)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=resnet_base.input, outputs=output)\n",
        "\n",
        "# Compile with Adam optimizer\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-6),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights_dict,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_steps=len(val_generator)\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "val_loss, val_acc = model.evaluate(val_generator, steps=len(val_generator))\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# Get predictions\n",
        "y_pred_probs = model.predict(val_generator, steps=len(val_generator))\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(val_generator.classes, y_pred)\n",
        "print(f\"Accuracy on Validation Set: {accuracy:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/custom_eye_disease_model.h5')\n",
        "print(\"Model saved successfully.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}