{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DinurakshanRavichandran/Visio-Glance/blob/Glaucoma-Model/glaucoma_V03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd473898",
      "metadata": {
        "id": "fd473898"
      },
      "source": [
        "# Enhanced Glaucoma Detection Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b3a2bd",
      "metadata": {
        "id": "61b3a2bd"
      },
      "source": [
        "\n",
        "## Steps to Improve Model Accuracy\n",
        "1. **Data Preprocessing**:\n",
        "    - Handling class imbalance with SMOTE (requires `imblearn` library).\n",
        "    - Scaling features using `StandardScaler`.\n",
        "2. **Model Training**:\n",
        "    - Using XGBoost with hyperparameter tuning via `GridSearchCV`.\n",
        "3. **Evaluation**:\n",
        "    - Reporting metrics including accuracy, precision, recall, and F1-score.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tZwS8VvRdt9",
        "outputId": "a950e009-474f-48a0-dbe5-1cbf74337235"
      },
      "id": "7tZwS8VvRdt9",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ff2efd2",
      "metadata": {
        "id": "1ff2efd2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "import re\n",
        "\n",
        "# Load your dataset here\n",
        "data = pd.read_csv('/content/drive/MyDrive/DSGP PROJECT 29/DATASETS/glaucoma_dataset.csv')\n",
        "print(data.columns)\n",
        "\n",
        "# Function to convert Visual Acuity (e.g., '20/40') to a numerical ratio (e.g., 0.5)\n",
        "def convert_visual_acuity(value):\n",
        "    try:\n",
        "        numerator, denominator = map(float, value.split('/'))\n",
        "        return numerator / denominator\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Function to extract numeric values from OCT Results column\n",
        "def extract_oct_features(value, feature_name):\n",
        "    try:\n",
        "        pattern = rf\"{feature_name}: ([\\d\\.]+)\"  # Regex pattern to extract numeric value\n",
        "        match = re.search(pattern, value)\n",
        "        return float(match.group(1)) if match else None\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Apply transformations\n",
        "data['Visual Acuity Measurements'] = data['Visual Acuity Measurements'].apply(convert_visual_acuity)\n",
        "\n",
        "# Create new columns for OCT numeric features\n",
        "data['RNFL Thickness'] = data['Optical Coherence Tomography (OCT) Results'].apply(\n",
        "    lambda x: extract_oct_features(x, 'RNFL Thickness'))\n",
        "data['GCC Thickness'] = data['Optical Coherence Tomography (OCT) Results'].apply(\n",
        "    lambda x: extract_oct_features(x, 'GCC Thickness'))\n",
        "data['Retinal Volume'] = data['Optical Coherence Tomography (OCT) Results'].apply(\n",
        "    lambda x: extract_oct_features(x, 'Retinal Volume'))\n",
        "data['Macular Thickness'] = data['Optical Coherence Tomography (OCT) Results'].apply(\n",
        "    lambda x: extract_oct_features(x, 'Macular Thickness'))\n",
        "\n",
        "# Drop the original OCT column and unnecessary ones\n",
        "data.drop(['Patient ID', 'Optical Coherence Tomography (OCT) Results'], axis=1, inplace=True)\n",
        "\n",
        "# Drop rows with missing or invalid data\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(['Glaucoma Type'], axis=1)\n",
        "y = data['Glaucoma Type']\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_columns = ['Gender', 'Family History', 'Medical History', 'Medication Usage',\n",
        "                       'Cataract Status', 'Angle Closure Status', 'Visual Symptoms', 'Diagnosis']\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "for col in categorical_columns:\n",
        "    X[col] = encoder.fit_transform(X[col])\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Handle class imbalance with SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the XGBoost model\n",
        "model = xgb.XGBClassifier(random_state=42)\n",
        "model.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6106e59",
      "metadata": {
        "id": "e6106e59"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define parameter grid for XGBoost\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [4, 6, 8],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'random_state': [42]\n",
        "}\n",
        "\n",
        "# Grid search for best parameters\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train_resampled)\n",
        "\n",
        "# Best model\n",
        "best_xgb = grid_search.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "832ad49f",
      "metadata": {
        "id": "832ad49f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Evaluate on test data\n",
        "y_pred = best_xgb.predict(X_test_scaled)\n",
        "\n",
        "# Classification report and accuracy\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}