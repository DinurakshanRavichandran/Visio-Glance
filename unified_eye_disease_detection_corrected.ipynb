{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DinurakshanRavichandran/Visio-Glance/blob/FINAL-MODEL-NLP/unified_eye_disease_detection_corrected.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu4m-h9MVrqx"
      },
      "source": [
        "# Unified Eye Disease Detection Model\n",
        "This notebook implements a machine learning pipeline to predict one of six eye diseases based on symptom datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts1N7Q17Vuyr",
        "outputId": "141024af-e4d3-462e-cd7b-5ea8f2efb992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQSK_xVJ_J3d"
      },
      "source": [
        "Load, Merge, Clean, and Save the Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN15p3NP_TZJ",
        "outputId": "17ea8203-c586-4657-c03d-2462d5364de4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset: /content/drive/MyDrive/PROJECT 29/FINAL MODEL/PRE-PROCESSED DATASETS/preprocessed_glaucoma_dataset.csv | Shape: (10000, 13)\n",
            "Loaded dataset: /content/drive/MyDrive/PROJECT 29/FINAL MODEL/PRE-PROCESSED DATASETS/Preprocessed_Cataract_Dataset.csv | Shape: (10000, 23)\n",
            "Loaded dataset: /content/drive/MyDrive/PROJECT 29/FINAL MODEL/PRE-PROCESSED DATASETS/Preprocessed_Diabetic_Retinopathy_Dataset.csv | Shape: (10000, 14)\n",
            "Loaded dataset: /content/drive/MyDrive/PROJECT 29/FINAL MODEL/PRE-PROCESSED DATASETS/Preprocessed_CNV_Detection_Dataset.csv | Shape: (10750, 20)\n",
            "Loaded dataset: /content/drive/MyDrive/PROJECT 29/FINAL MODEL/PRE-PROCESSED DATASETS/Preprocessed_DME_Dataset.csv | Shape: (10000, 19)\n",
            "Loaded dataset: /content/drive/MyDrive/PROJECT 29/FINAL MODEL/PRE-PROCESSED DATASETS/Preprocessed_Drusen_Dataset.csv | Shape: (10000, 12)\n",
            "\n",
            "Merged dataset shape (before cleaning): (60750, 74)\n",
            "\n",
            "Missing values before handling:\n",
            " Age                                          0\n",
            "Intraocular Pressure (IOP)               40750\n",
            "Cup-to-Disc Ratio (CDR)                  50750\n",
            "Pachymetry                               50750\n",
            "Diagnosis                                    0\n",
            "                                         ...  \n",
            "Cholesterol Levels                       50750\n",
            "Visual Symptoms_blind spots              50750\n",
            "Visual Symptoms_light sensitivity        50750\n",
            "Visual Symptoms_night vision problems    50750\n",
            "Visual Symptoms_vision change            50750\n",
            "Length: 74, dtype: int64\n",
            "Dropped columns with >50% missing values (excluding essential features): ['Cotton Wool Spots Count', 'LDL Cholesterol']\n",
            "\n",
            "Missing values after handling:\n",
            " 0\n",
            "Dataset shape after removing duplicates: (53717, 72)\n",
            "Final dataset saved to: /content/drive/MyDrive/PROJECT 29/FINAL MODEL/merged_dataset.csv\n",
            "\n",
            "Final dataset shape: (53717, 72)\n",
            "\n",
            "Diagnosis Value Counts:\n",
            "Diagnosis\n",
            "0    27634\n",
            "1    26083\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Disease Label Value Counts:\n",
            "Disease_Label\n",
            "Glaucoma                10000\n",
            "Diabetic Retinopathy    10000\n",
            "Drusen                   9999\n",
            "Cataract                 9844\n",
            "DME                      8573\n",
            "CNV                      5301\n",
            "Name: count, dtype: int64\n",
            "Dropped features: ['Visual Symptoms_vomiting', 'Visual Symptoms_nausea', 'Visual Symptoms_eye pain', 'Visual Symptoms_vision loss', 'Visual Symptoms_general vision blurriness', 'Visual Symptoms_vision change', 'Visual Symptoms_vision loss area', 'Visual Symptoms_loss of central vision', 'Visual Symptoms_temporary vision disturbances', 'Visual Symptoms_colors appear faded']\n",
            "Encoded dataset saved to: /content/drive/MyDrive/PROJECT 29/FINAL MODEL/encoded_merged_dataset.csv\n",
            "   Disease_Label\n",
            "0              0\n",
            "1              0\n",
            "2              0\n",
            "3              0\n",
            "4              0\n",
            "5              0\n",
            "6              0\n",
            "7              0\n",
            "8              0\n",
            "9              0\n",
            "/n\n",
            "Final dataset shape: (53717, 62)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define dataset paths and labels\n",
        "datasets = {\n",
        "    \"/content/drive/MyDrive/PROJECT 29/FINAL MODEL/PRE-PROCESSED DATASETS/preprocessed_glaucoma_dataset.csv\": \"Glaucoma\",\n",
        "    \"/content/drive/MyDrive/PROJECT 29/FINAL MODEL/PRE-PROCESSED DATASETS/Preprocessed_Cataract_Dataset.csv\": \"Cataract\",\n",
        "    \"/content/drive/MyDrive/PROJECT 29/FINAL MODEL/PRE-PROCESSED DATASETS/Preprocessed_Diabetic_Retinopathy_Dataset.csv\": \"Diabetic Retinopathy\",\n",
        "    \"/content/drive/MyDrive/PROJECT 29/FINAL MODEL/PRE-PROCESSED DATASETS/Preprocessed_CNV_Detection_Dataset.csv\": \"CNV\",\n",
        "    \"/content/drive/MyDrive/PROJECT 29/FINAL MODEL/PRE-PROCESSED DATASETS/Preprocessed_DME_Dataset.csv\": \"DME\",\n",
        "    \"/content/drive/MyDrive/PROJECT 29/FINAL MODEL/PRE-PROCESSED DATASETS/Preprocessed_Drusen_Dataset.csv\": \"Drusen\"\n",
        "}\n",
        "\n",
        "\n",
        "# Step 1: Load datasets into a list\n",
        "dataframes = []\n",
        "for file, disease in datasets.items():\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        print(f\"Loaded dataset: {file} | Shape: {df.shape}\")\n",
        "        df[\"Disease_Label\"] = disease  # Add disease label column\n",
        "        dataframes.append(df)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file}: {e}\")\n",
        "\n",
        "# Step 2: Merge all datasets while keeping all columns\n",
        "merged_df = pd.concat(dataframes, ignore_index=True, sort=False)  # Keeps unique columns\n",
        "print(f\"\\nMerged dataset shape (before cleaning): {merged_df.shape}\")\n",
        "\n",
        "# -----------------------------------------\n",
        "# Step 3: Handling missing values\n",
        "# -----------------------------------------\n",
        "\n",
        "# Check for missing values before handling\n",
        "print(\"\\nMissing values before handling:\\n\", merged_df.isnull().sum())\n",
        "\n",
        "# ðŸ”¹ Essential Disease-Specific Features (Ensure They Are Kept)\n",
        "essential_features = [\n",
        "    \"Intraocular Pressure (IOP)\", \"Cup-to-Disc Ratio (CDR)\", \"Pachymetry\",\n",
        "    \"Retinal Thickness\", 'History of Diabetes',\n",
        "    \"Microaneurysms Count\", \"Hemorrhages Count\", \"BMI\", \"Blood Pressure\",\n",
        "    \"Cholesterol Levels\"\n",
        "]\n",
        "\n",
        "# ðŸ”¹ Disease-Specific Features - Fill missing values per disease\n",
        "disease_specific_features = {\n",
        "    \"Glaucoma\": [\"Cup-to-Disc Ratio (CDR)\", \"Pachymetry\"],\n",
        "    \"Cataract\": [\"History of Diabetes\"],\n",
        "    \"Diabetic Retinopathy\": [\"Retinal Thickness\", \"Cotton Wool Spots Count\", \"LDL Cholesterol\", \"Microaneurysms Count\", \"Hemorrhages Count\"],\n",
        "    \"Drusen\": [\"BMI\", \"Blood Pressure\", \"Cholesterol Levels\"]\n",
        "}\n",
        "\n",
        "for disease, features in disease_specific_features.items():\n",
        "    for col in features:\n",
        "        if col in merged_df.columns:\n",
        "            disease_mean = merged_df.loc[merged_df[\"Disease_Label\"] == disease, col].mean()\n",
        "\n",
        "            # If the mean is NaN, use the global median\n",
        "            if pd.isna(disease_mean):\n",
        "                merged_df[col].fillna(merged_df[col].median(), inplace=True)\n",
        "            else:\n",
        "                merged_df.loc[merged_df[\"Disease_Label\"] == disease, col] = (\n",
        "                    merged_df.loc[merged_df[\"Disease_Label\"] == disease, col].fillna(disease_mean)\n",
        "                )\n",
        "\n",
        "# ðŸ”¹ Common Features - Fill missing values per disease group\n",
        "common_features = {\n",
        "    \"Glaucoma_DME\": [\"Intraocular Pressure (IOP)\"],\n",
        "    \"Cataract_DiabeticRetinopathy_Drusen_CNV\": [\"Smoking Status\"]\n",
        "}\n",
        "\n",
        "for col in common_features[\"Glaucoma_DME\"]:\n",
        "    if col in merged_df.columns:\n",
        "        merged_df[col] = merged_df.groupby(\"Disease_Label\")[col].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "for col in common_features[\"Cataract_DiabeticRetinopathy_Drusen_CNV\"]:\n",
        "    if col in merged_df.columns:\n",
        "        merged_df[col] = merged_df[col].fillna(merged_df[col].mode()[0])\n",
        "\n",
        "# ðŸ”¹ Handle Missing Values for Other Disease Groups Using Median\n",
        "for col in essential_features:\n",
        "    if col in merged_df.columns:\n",
        "        merged_df[col] = merged_df[col].fillna(merged_df[col].median())\n",
        "\n",
        "# ðŸ”¹ One-Hot Encoded Features - Fill missing with 0 (category not applicable)\n",
        "one_hot_encoded_features = [\n",
        "    \"Lens Opacity_mild\", \"Lens Opacity_moderate\", \"Lens Opacity_severe\",\n",
        "    \"Glare Sensitivity_mild\", \"Glare Sensitivity_none\", \"Glare Sensitivity_severe\",\n",
        "    \"UV Exposure_high\", \"UV Exposure_low\", \"UV Exposure_medium\",\n",
        "    \"Lens Status_Cortical cataract\", \"Lens Status_Normal\", \"Lens Status_Nuclear cataract\", \"Lens Status_Posterior subcapsular cataract\",\n",
        "    \"Optical Coherence Tomography (OCT) Results_Early CNV\", \"Optical Coherence Tomography (OCT) Results_Normal\", \"Optical Coherence Tomography (OCT) Results_Scarred/End-stage CNV\",\n",
        "    \"Fluorescein Angiography Results_Early Neovascularization\", \"Fluorescein Angiography Results_No Neovascularization\"\n",
        "]\n",
        "\n",
        "for col in one_hot_encoded_features:\n",
        "    if col in merged_df.columns:\n",
        "        merged_df[col] = merged_df[col].fillna(0)\n",
        "\n",
        "# ðŸ”¹ Visual Symptoms - Fill missing values with 0\n",
        "symptom_columns = [col for col in merged_df.columns if \"Visual Symptoms_\" in col]\n",
        "merged_df[symptom_columns] = merged_df[symptom_columns].fillna(0)\n",
        "\n",
        "# ðŸ”¹ Visual Acuity Test Results - Fill missing with 0 (category not applicable)\n",
        "acuity_columns = [col for col in merged_df.columns if \"Visual Acuity Test Results_\" in col]\n",
        "merged_df[acuity_columns] = merged_df[acuity_columns].fillna(0)\n",
        "\n",
        "# ðŸ”¹ Drop Features That Still Have >50% Missing Values (Except Essential Features)\n",
        "missing_percent = merged_df.isnull().sum() / len(merged_df) * 100\n",
        "cols_to_drop = missing_percent[missing_percent > 50].index.tolist()\n",
        "cols_to_drop = [col for col in cols_to_drop if col not in essential_features]\n",
        "merged_df.drop(columns=cols_to_drop, inplace=True)\n",
        "print(f\"Dropped columns with >50% missing values (excluding essential features): {list(cols_to_drop)}\")\n",
        "\n",
        "# ðŸ”¹ Final check for missing values\n",
        "print(\"\\nMissing values after handling:\\n\", merged_df.isnull().sum().sum())\n",
        "\n",
        "# -----------------------------------------\n",
        "# Step 4: Remove duplicate rows\n",
        "# -----------------------------------------\n",
        "merged_df.drop_duplicates(inplace=True)\n",
        "print(f\"Dataset shape after removing duplicates: {merged_df.shape}\")\n",
        "\n",
        "# -----------------------------------------\n",
        "# Step 5: Save the cleaned dataset\n",
        "# -----------------------------------------\n",
        "output_path = \"/content/drive/MyDrive/PROJECT 29/FINAL MODEL/merged_dataset.csv\"\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "print(f\"Final dataset saved to: {output_path}\")\n",
        "\n",
        "# -----------------------------------------\n",
        "# Additional Checks\n",
        "# -----------------------------------------\n",
        "print(\"\\nFinal dataset shape:\", merged_df.shape)\n",
        "\n",
        "#print value counts for diagnosis and disease labels\n",
        "print(\"\\nDiagnosis Value Counts:\")\n",
        "print(merged_df[\"Diagnosis\"].value_counts())\n",
        "\n",
        "print(\"\\nDisease Label Value Counts:\")\n",
        "print(merged_df[\"Disease_Label\"].value_counts())\n",
        "\n",
        "\n",
        "# ðŸ”¹ Define disease encoding\n",
        "disease_mapping = {\n",
        "    \"Glaucoma\": 0,\n",
        "    \"Cataract\": 1,\n",
        "    \"Diabetic Retinopathy\": 2,\n",
        "    \"CNV\": 3,\n",
        "    \"DME\": 4,\n",
        "    \"Drusen\": 5\n",
        "}\n",
        "\n",
        "# ðŸ”¹ Apply encoding to Disease_Label column\n",
        "merged_df[\"Disease_Label\"] = merged_df[\"Disease_Label\"].map(disease_mapping)\n",
        "\n",
        "# ðŸ”¹ Drop the specified Visual Symptoms features\n",
        "features_to_drop = [\n",
        "    \"Visual Symptoms_vomiting\", \"Visual Symptoms_nausea\", \"Visual Symptoms_eye pain\",\n",
        "    \"Visual Symptoms_vision loss\", \"Visual Symptoms_general vision blurriness\",\n",
        "    \"Visual Symptoms_vision change\", \"Visual Symptoms_vision loss area\",\n",
        "    \"Visual Symptoms_loss of central vision\", \"Visual Symptoms_temporary vision disturbances\",\n",
        "    \"Visual Symptoms_colors appear faded\"\n",
        "]\n",
        "\n",
        "# Drop columns if they exist in the dataframe\n",
        "merged_df.drop(columns=[col for col in features_to_drop if col in merged_df.columns], inplace=True)\n",
        "\n",
        "print(f\"Dropped features: {features_to_drop}\")\n",
        "\n",
        "\n",
        "# ðŸ”¹ Save the new encoded dataset\n",
        "encoded_output_path = \"/content/drive/MyDrive/PROJECT 29/FINAL MODEL/encoded_merged_dataset.csv\"\n",
        "merged_df.to_csv(encoded_output_path, index=False)\n",
        "\n",
        "print(f\"Encoded dataset saved to: {encoded_output_path}\")\n",
        "\n",
        "# ðŸ”¹ Verify the encoding\n",
        "print(merged_df[[\"Disease_Label\"]].head(10))  # Print first 10 rows to check encoding\n",
        "\n",
        "print(\"/n\")\n",
        "#print final dataset shape\n",
        "print(\"Final dataset shape:\", merged_df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWdm7C4hjts8",
        "outputId": "009cb759-e1de-4668-f196-2eaf4cd37544"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing Multi-Output Classification with XGBoost."
      ],
      "metadata": {
        "id": "qmITGIu-5OuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ðŸ”¹ Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/TEST 29/encoded_merged_dataset.csv\")\n",
        "\n",
        "# ðŸ”¹ Define features & target variables\n",
        "X = df.drop(columns=[\"Diagnosis\", \"Disease_Label\"])  # Features\n",
        "y = df[[\"Diagnosis\", \"Disease_Label\"]]  # Multi-output target (binary + multi-class)\n",
        "\n",
        "# -----------------------------------------\n",
        "# Step 1: Train-Validation-Test Split (70-15-15) with Stratification\n",
        "# -----------------------------------------\n",
        "\n",
        "# First, split into 85% Train+Validation and 15% Test\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y, test_size=0.15, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Now, split Train+Validation into 70% Train and 15% Validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.1765, random_state=42, stratify=y_train_val\n",
        ")\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"Training Set: {X_train.shape}, Validation Set: {X_val.shape}, Test Set: {X_test.shape}\")\n",
        "\n",
        "# -----------------------------------------\n",
        "# Step 2: Handle Class Imbalance for Diagnosis using SMOTE\n",
        "# -----------------------------------------\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled_diagnosis = smote.fit_resample(X_train, y_train[\"Diagnosis\"])\n",
        "\n",
        "# -----------------------------------------\n",
        "# Step 3: Remove Feature Leakage for Disease_Label\n",
        "# -----------------------------------------\n",
        "X_train_no_diag = X_train\n",
        "X_val_no_diag = X_val\n",
        "X_test_no_diag = X_test\n",
        "\n",
        "# -----------------------------------------\n",
        "# Step 4: Hyperparameter Tuning using Validation Set\n",
        "# -----------------------------------------\n",
        "\n",
        "# ðŸ”¹ Define XGBoost Parameter Grid\n",
        "param_grid = {\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
        "    \"n_estimators\": [100, 200, 300],\n",
        "    \"subsample\": [0.7, 1.0],\n",
        "    \"colsample_bytree\": [0.7, 1.0]\n",
        "}\n",
        "\n",
        "# ðŸ”¹ Cross-Validation Setup\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# ðŸ”¹ Hyperparameter tuning for Diagnosis\n",
        "xgb_diagnosis_tuned = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric=\"logloss\", use_label_encoder=False)\n",
        "grid_search_diagnosis = GridSearchCV(xgb_diagnosis_tuned, param_grid, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_search_diagnosis.fit(X_train_resampled, y_train_resampled_diagnosis)\n",
        "\n",
        "# ðŸ”¹ Hyperparameter tuning for Disease_Label (multi-class)\n",
        "xgb_disease_tuned = xgb.XGBClassifier(objective=\"multi:softmax\", num_class=6, eval_metric=\"mlogloss\", use_label_encoder=False)\n",
        "grid_search_disease = GridSearchCV(xgb_disease_tuned, param_grid, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "grid_search_disease.fit(X_train_no_diag, y_train[\"Disease_Label\"])\n",
        "\n",
        "# ðŸ”¹ Get Best Models\n",
        "best_diagnosis_model = grid_search_diagnosis.best_estimator_\n",
        "best_disease_model = grid_search_disease.best_estimator_\n",
        "\n",
        "# -----------------------------------------\n",
        "# Step 5: Train Final Models with Best Hyperparameters\n",
        "# -----------------------------------------\n",
        "\n",
        "best_diagnosis_model.fit(X_train_resampled, y_train_resampled_diagnosis)\n",
        "best_disease_model.fit(X_train_no_diag, y_train[\"Disease_Label\"])\n",
        "\n",
        "# -----------------------------------------\n",
        "# Step 6: Evaluate Model Performance\n",
        "# -----------------------------------------\n",
        "\n",
        "# ðŸ”¹ Training Predictions\n",
        "y_train_pred_diagnosis = best_diagnosis_model.predict(X_train_resampled)\n",
        "y_train_pred_disease = best_disease_model.predict(X_train_no_diag)\n",
        "\n",
        "# ðŸ”¹ Validation Predictions (for hyperparameter tuning)\n",
        "y_val_pred_diagnosis = best_diagnosis_model.predict(X_val)\n",
        "y_val_pred_disease = best_disease_model.predict(X_val_no_diag)\n",
        "\n",
        "# ðŸ”¹ Test Predictions (final evaluation)\n",
        "y_test_pred_diagnosis = best_diagnosis_model.predict(X_test)\n",
        "y_test_pred_disease = best_disease_model.predict(X_test_no_diag)\n",
        "\n",
        "# -----------------------------------------\n",
        "# Step 7: Compute Accuracies\n",
        "# -----------------------------------------\n",
        "\n",
        "# ðŸ”¹ Training Accuracy\n",
        "train_acc_diagnosis = accuracy_score(y_train_resampled_diagnosis, y_train_pred_diagnosis) * 100\n",
        "train_acc_disease = accuracy_score(y_train[\"Disease_Label\"], y_train_pred_disease) * 100\n",
        "\n",
        "# ðŸ”¹ Validation Accuracy\n",
        "val_acc_diagnosis = accuracy_score(y_val[\"Diagnosis\"], y_val_pred_diagnosis) * 100\n",
        "val_acc_disease = accuracy_score(y_val[\"Disease_Label\"], y_val_pred_disease) * 100\n",
        "\n",
        "# ðŸ”¹ Test Accuracy\n",
        "test_acc_diagnosis = accuracy_score(y_test[\"Diagnosis\"], y_test_pred_diagnosis) * 100\n",
        "test_acc_disease = accuracy_score(y_test[\"Disease_Label\"], y_test_pred_disease) * 100\n",
        "\n",
        "# Print results\n",
        "print(\"\\nðŸ”¹ Training Accuracy:\")\n",
        "print(f\"  - Diagnosis: {train_acc_diagnosis:.2f}%\")\n",
        "print(f\"  - Disease_Label: {train_acc_disease:.2f}%\")\n",
        "\n",
        "print(\"\\nðŸ”¹ Validation Accuracy:\")\n",
        "print(f\"  - Diagnosis: {val_acc_diagnosis:.2f}%\")\n",
        "print(f\"  - Disease_Label: {val_acc_disease:.2f}%\")\n",
        "\n",
        "print(\"\\nðŸ”¹ Test Accuracy:\")\n",
        "print(f\"  - Diagnosis: {test_acc_diagnosis:.2f}%\")\n",
        "print(f\"  - Disease_Label: {test_acc_disease:.2f}%\")\n",
        "\n",
        "# -----------------------------------------\n",
        "# Step 8: Classification Reports\n",
        "# -----------------------------------------\n",
        "\n",
        "print(\"\\nðŸ”¹ Classification Report for Diagnosis (Binary Classification)\")\n",
        "print(classification_report(y_test[\"Diagnosis\"], y_test_pred_diagnosis, target_names=[\"Healthy (0)\", \"Disease (1)\"]))\n",
        "\n",
        "print(\"\\nðŸ”¹ Classification Report for Disease_Label (Multi-Class Classification)\")\n",
        "disease_classes = [\"Glaucoma (0)\", \"Cataract (1)\", \"Diabetic Retinopathy (2)\", \"CNV (3)\", \"DME (4)\", \"Drusen (5)\"]\n",
        "print(classification_report(y_test[\"Disease_Label\"], y_test_pred_disease, target_names=disease_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReVTpyrP5jrJ",
        "outputId": "b6103bc9-afc2-4b78-e2be-6479fdeeb863"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set: (37600, 60), Validation Set: (8059, 60), Test Set: (8058, 60)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [07:33:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:18:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:19:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:19:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ Training Accuracy:\n",
            "  - Diagnosis: 83.68%\n",
            "  - Disease_Label: 99.95%\n",
            "\n",
            "ðŸ”¹ Validation Accuracy:\n",
            "  - Diagnosis: 73.15%\n",
            "  - Disease_Label: 99.95%\n",
            "\n",
            "ðŸ”¹ Test Accuracy:\n",
            "  - Diagnosis: 72.98%\n",
            "  - Disease_Label: 99.95%\n",
            "\n",
            "ðŸ”¹ Classification Report for Diagnosis (Binary Classification)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Healthy (0)       0.74      0.74      0.74      4146\n",
            " Disease (1)       0.72      0.72      0.72      3912\n",
            "\n",
            "    accuracy                           0.73      8058\n",
            "   macro avg       0.73      0.73      0.73      8058\n",
            "weighted avg       0.73      0.73      0.73      8058\n",
            "\n",
            "\n",
            "ðŸ”¹ Classification Report for Disease_Label (Multi-Class Classification)\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "            Glaucoma (0)       1.00      1.00      1.00      1500\n",
            "            Cataract (1)       1.00      1.00      1.00      1477\n",
            "Diabetic Retinopathy (2)       1.00      1.00      1.00      1500\n",
            "                 CNV (3)       0.99      1.00      1.00       795\n",
            "                 DME (4)       1.00      1.00      1.00      1286\n",
            "              Drusen (5)       1.00      1.00      1.00      1500\n",
            "\n",
            "                accuracy                           1.00      8058\n",
            "               macro avg       1.00      1.00      1.00      8058\n",
            "            weighted avg       1.00      1.00      1.00      8058\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}