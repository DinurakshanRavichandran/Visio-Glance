{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkCc1lm0tbKM+YRWeYeL0w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DinurakshanRavichandran/Visio-Glance/blob/XAI/LIME_for_custom_one.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5NFndNgEuSb"
      },
      "outputs": [],
      "source": [
        "!pip install lime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('/content/custom_eye_disease_model.h5', compile=False)\n",
        "\n",
        "# Select a random index from the validation dataset\n",
        "random_index = random.randint(0, len(val_generator.filepaths) - 1)\n",
        "sample_image_path = val_generator.filepaths[random_index]\n",
        "\n",
        "# Load and preprocess the image\n",
        "img = load_img(sample_image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "img_array = img_to_array(img) / 255.0  # Normalize\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Print the selected index\n",
        "print(f\"Selected validation data index: {random_index}\")\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Selected Image (Index: {random_index})\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Define LIME image explainer\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "# Function to predict probabilities for LIME\n",
        "def predict_fn(images):\n",
        "    images = np.array(images)\n",
        "    return model.predict([images, images])  # Since the model has dual inputs\n",
        "\n",
        "# Generate explanation for the selected image\n",
        "explanation = explainer.explain_instance(\n",
        "    img_array[0],  # LIME requires a single image (not batch)\n",
        "    predict_fn,\n",
        "    top_labels=4,  # Explain the 4 predicted classes\n",
        "    hide_color=0,\n",
        "    num_samples=1000  # Number of perturbed samples to generate\n",
        ")\n",
        "\n",
        "# Get the explanation for the predicted class\n",
        "top_predicted_class = explanation.top_labels[0]\n",
        "\n",
        "# Get the highlighted regions for positive influence\n",
        "temp, mask = explanation.get_image_and_mask(\n",
        "    top_predicted_class,\n",
        "    positive_only=True,\n",
        "    num_features=5,  # Number of superpixels to highlight\n",
        "    hide_rest=False\n",
        ")\n",
        "\n",
        "# Convert mask to 8-bit format (0-255) for OpenCV\n",
        "heatmap = np.uint8(255 * mask)\n",
        "\n",
        "# Apply color mapping to create a heatmap\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)  # Apply colormap\n",
        "heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "\n",
        "# Convert both images to float32 for blending\n",
        "temp_float = temp.astype(np.float32)  # Convert image to float\n",
        "heatmap_float = heatmap.astype(np.float32) / 255.0  # Normalize heatmap\n",
        "\n",
        "# Blend the heatmap with the original image\n",
        "alpha = 0.5  # Transparency level\n",
        "heatmap_overlay = cv2.addWeighted(temp_float, 0.6, heatmap_float, alpha, 0)\n",
        "\n",
        "# Extract only important regions\n",
        "important_regions = temp * mask[:, :, np.newaxis]  # Keep only highlighted parts\n",
        "\n",
        "# Plot all results\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Original Image\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "# LIME with Mark Boundaries\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(mark_boundaries(temp, mask))\n",
        "plt.title(f\"LIME Explanation (Class: {CATEGORIES[top_predicted_class]})\")\n",
        "plt.axis('off')\n",
        "\n",
        "# Heatmap Overlay\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(heatmap_overlay)\n",
        "plt.title(\"Heatmap Overlay\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Plot important regions separately\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(important_regions)\n",
        "plt.title(\"Only Important Regions\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ]
}