{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DinurakshanRavichandran/Visio-Glance/blob/OCT-eye-disease-detection/CourseworkModel2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EGyJ6kfxehm"
      },
      "source": [
        "1. Set Up Your Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLVYWsnOxiuS",
        "outputId": "c9df6183-8aa1-410c-d7ed-f5e266841a0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment ready!\n"
          ]
        }
      ],
      "source": [
        "# Core Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import Average\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# For reproducibility\n",
        "import random\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"Environment ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GE3p7wiy38e",
        "outputId": "d6ca6a5a-42e3-46b8-b564-58dacfd934cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset unzipped successfully!\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "# Path to the zipped dataset in your Drive\n",
        "zip_path = '/content/drive/MyDrive/Machine learning/Dataset/OCT Dataset/Train/archive.zip'\n",
        "\n",
        "# Set extraction path in Colab\n",
        "extract_path = '/content/OCT_Dataset'\n",
        "\n",
        "# Unzipping the dataset\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Dataset unzipped successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOp5CQG7xmCB"
      },
      "source": [
        "2. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idz9gr8KzI76"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eJ73b0Py01u",
        "outputId": "0c1d46a8-a6e9-4e8d-9a2d-e9f31c6d8eff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data limited to 8,000 images per class.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "def limit_images_per_class(src_dir, dest_dir, max_images=8000):\n",
        "    \"\"\"\n",
        "    Copies a limited number of images from source to destination for each class.\n",
        "    Parameters:\n",
        "        src_dir (str): Source directory where the images are stored.\n",
        "        dest_dir (str): Destination directory to store the limited images.\n",
        "        max_images (int): Maximum number of images per class.\n",
        "    \"\"\"\n",
        "    # Ensure destination directory exists\n",
        "    if not os.path.exists(dest_dir):\n",
        "        os.makedirs(dest_dir)\n",
        "\n",
        "    # Iterate through each class folder in the source directory\n",
        "    for category in os.listdir(src_dir):\n",
        "        category_path = os.path.join(src_dir, category)\n",
        "        dest_category_path = os.path.join(dest_dir, category)\n",
        "\n",
        "        if not os.path.exists(dest_category_path):\n",
        "            os.makedirs(dest_category_path)\n",
        "\n",
        "        # Get list of images\n",
        "        images = [\n",
        "            os.path.join(category_path, img)\n",
        "            for img in os.listdir(category_path)\n",
        "            if img.endswith(('.jpeg', '.jpg', '.png'))\n",
        "        ]\n",
        "\n",
        "        # Shuffle and select limited images\n",
        "        random.shuffle(images)\n",
        "        limited_images = images[:max_images]\n",
        "\n",
        "        # Copy limited images to destination folder\n",
        "        for img_path in limited_images:\n",
        "            shutil.copy(img_path, os.path.join(dest_category_path, os.path.basename(img_path)))\n",
        "\n",
        "# Source and destination paths\n",
        "src_train_dir = '/content/OCT_Dataset/OCT2017 /train'\n",
        "dest_train_dir = '/content/OCT_Dataset/OCT2017 /train_limited'\n",
        "\n",
        "# Apply the function\n",
        "limit_images_per_class(src_train_dir, dest_train_dir, max_images=8000)\n",
        "\n",
        "print(\"Training data limited to 8,000 images per class.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ILiQ0lqkx4mt"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/OCT_Dataset/OCT2017 /train_limited'\n",
        "val_dir = '/content/OCT_Dataset/OCT2017 /val'\n",
        "test_dir = '/content/OCT_Dataset/OCT2017 /test'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LDSowgyx7Uk"
      },
      "source": [
        "Define Data Generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9MJpgCkyAuq",
        "outputId": "c164a095-8978-40fa-dec0-c55f3a54a7e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 32000 images belonging to 4 classes.\n",
            "Found 32 images belonging to 4 classes.\n",
            "Found 968 images belonging to 4 classes.\n",
            "Enhanced data generators are ready!\n"
          ]
        }
      ],
      "source": [
        "# Define image dimensions and batch size\n",
        "img_height, img_width = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Training data generator with combined augmentation techniques\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,          # Normalize pixel values\n",
        "    rotation_range=20,          # Random rotation (enhanced from 15)\n",
        "    width_shift_range=0.2,      # Random horizontal shifts (enhanced from 0.1)\n",
        "    height_shift_range=0.2,     # Random vertical shifts (enhanced from 0.1)\n",
        "    shear_range=0.2,            # Random shearing (added)\n",
        "    zoom_range=0.2,             # Random zoom (enhanced from 0.1)\n",
        "    horizontal_flip=True,       # Random horizontal flipping\n",
        "    fill_mode='nearest',         # Filling mode for shifted pixels\n",
        "    brightness_range=(0.8, 1.2),  # Brightness adjustment\n",
        "    channel_shift_range=0.2       # Channel shifting\n",
        ")\n",
        "\n",
        "# Validation and testing data generators (only normalization, no augmentation)\n",
        "val_test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "# Training data generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,                  # Training directory\n",
        "    target_size=(img_height, img_width),  # Resize images\n",
        "    batch_size=batch_size,      # Batch size\n",
        "    class_mode='categorical'    # For multi-class classification\n",
        ")\n",
        "\n",
        "# Validation data generator\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    val_dir,                    # Validation directory\n",
        "    target_size=(img_height, img_width),  # Resize images\n",
        "    batch_size=batch_size,      # Batch size\n",
        "    class_mode='categorical'    # For multi-class classification\n",
        ")\n",
        "\n",
        "# Test data generator\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_dir,               # Testing directory\n",
        "    target_size=(img_height, img_width),  # Resize images\n",
        "    batch_size=batch_size,      # Batch size\n",
        "    class_mode='categorical'    # For multi-class classification\n",
        ")\n",
        "\n",
        "print(\"Enhanced data generators are ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lhaJYtTyDZ_"
      },
      "source": [
        "4. Train Individual Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hjFCN-J_yHBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7272f86d-21e2-4e3c-aa6b-0f8cf43f7007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Epoch 1/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 577ms/step - accuracy: 0.2535 - loss: 1.4111 - val_accuracy: 0.2500 - val_loss: 1.3869\n",
            "Epoch 2/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 552ms/step - accuracy: 0.2499 - loss: 1.3907 - val_accuracy: 0.2500 - val_loss: 1.3868\n",
            "Epoch 3/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m557s\u001b[0m 547ms/step - accuracy: 0.2535 - loss: 1.3871 - val_accuracy: 0.2500 - val_loss: 1.3864\n",
            "Epoch 4/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 549ms/step - accuracy: 0.2505 - loss: 1.3872 - val_accuracy: 0.2500 - val_loss: 1.3864\n",
            "Epoch 5/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 540ms/step - accuracy: 0.2574 - loss: 1.3874 - val_accuracy: 0.2500 - val_loss: 1.3865\n",
            "Epoch 6/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 540ms/step - accuracy: 0.2505 - loss: 1.3866 - val_accuracy: 0.2500 - val_loss: 1.3863\n",
            "Epoch 7/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 537ms/step - accuracy: 0.2490 - loss: 1.3864 - val_accuracy: 0.2500 - val_loss: 1.3870\n",
            "Epoch 8/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 535ms/step - accuracy: 0.2502 - loss: 1.3870 - val_accuracy: 0.2500 - val_loss: 1.3863\n",
            "Epoch 9/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 533ms/step - accuracy: 0.2502 - loss: 1.3863 - val_accuracy: 0.2500 - val_loss: 1.3863\n",
            "Epoch 10/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 527ms/step - accuracy: 0.2480 - loss: 1.3863 - val_accuracy: 0.2500 - val_loss: 1.3863\n",
            "Epoch 11/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 530ms/step - accuracy: 0.2473 - loss: 1.3863 - val_accuracy: 0.2500 - val_loss: 1.3863\n",
            "Epoch 12/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 526ms/step - accuracy: 0.2431 - loss: 1.3863 - val_accuracy: 0.2500 - val_loss: 1.3863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "def fine_tune_efficientnet():\n",
        "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    # Unfreeze some layers for fine-tuning\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers[:200]:  # Freeze first 200 layers (adjustable)\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)  # Dropout for regularization\n",
        "    output = layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    # Compile with a lower learning rate\n",
        "    optimizer = optimizers.Adam(learning_rate=1e-4)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "efficientnet_model = fine_tune_efficientnet()\n",
        "history_efficientnet = efficientnet_model.fit(train_generator, validation_data=val_generator, epochs=12)\n",
        "efficientnet_model.save('fine_tuned_efficientnet.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RENem0hsyKra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c95472a-4385-4451-d34d-51524e01482d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Epoch 1/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m592s\u001b[0m 564ms/step - accuracy: 0.3914 - loss: 1.2745 - val_accuracy: 0.3125 - val_loss: 5.8072\n",
            "Epoch 2/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 575ms/step - accuracy: 0.5320 - loss: 1.0769 - val_accuracy: 0.5938 - val_loss: 0.9632\n",
            "Epoch 3/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 568ms/step - accuracy: 0.5742 - loss: 0.9895 - val_accuracy: 0.4375 - val_loss: 1.4035\n",
            "Epoch 4/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m610s\u001b[0m 557ms/step - accuracy: 0.6012 - loss: 0.9422 - val_accuracy: 0.5312 - val_loss: 1.0157\n",
            "Epoch 5/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 554ms/step - accuracy: 0.6258 - loss: 0.8929 - val_accuracy: 0.5938 - val_loss: 1.8408\n",
            "Epoch 6/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 548ms/step - accuracy: 0.6385 - loss: 0.8729 - val_accuracy: 0.8125 - val_loss: 0.6564\n",
            "Epoch 7/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 556ms/step - accuracy: 0.6526 - loss: 0.8380 - val_accuracy: 0.6562 - val_loss: 0.8641\n",
            "Epoch 8/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 549ms/step - accuracy: 0.6637 - loss: 0.8230 - val_accuracy: 0.6250 - val_loss: 1.1007\n",
            "Epoch 9/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 553ms/step - accuracy: 0.6720 - loss: 0.7989 - val_accuracy: 0.6875 - val_loss: 0.9964\n",
            "Epoch 10/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 547ms/step - accuracy: 0.6871 - loss: 0.7726 - val_accuracy: 0.5625 - val_loss: 1.0754\n",
            "Epoch 11/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 547ms/step - accuracy: 0.6991 - loss: 0.7551 - val_accuracy: 0.8125 - val_loss: 0.4664\n",
            "Epoch 12/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 548ms/step - accuracy: 0.7058 - loss: 0.7353 - val_accuracy: 0.8125 - val_loss: 0.4500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "def fine_tune_resnet():\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    # Unfreeze last few layers for fine-tuning\n",
        "    for layer in base_model.layers[:143]:  # Freeze first 143 layers (adjustable)\n",
        "        layer.trainable = False\n",
        "    for layer in base_model.layers[143:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    x = base_model.output\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)  # Dropout for regularization\n",
        "    output = layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    # Compile with a low learning rate for fine-tuning\n",
        "    optimizer = optimizers.Adam(learning_rate=1e-4)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "resnet_model = fine_tune_resnet()\n",
        "history_resnet = resnet_model.fit(train_generator, validation_data=val_generator, epochs=12)\n",
        "resnet_model.save('fine_tuned_resnet.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbmHdzIAyNLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1840a8c1-f8ee-4f57-8be7-5266a6219c80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m661s\u001b[0m 627ms/step - accuracy: 0.6589 - loss: 0.8312 - val_accuracy: 0.9062 - val_loss: 0.3138\n",
            "Epoch 2/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m647s\u001b[0m 608ms/step - accuracy: 0.7702 - loss: 0.6000 - val_accuracy: 0.9062 - val_loss: 0.3083\n",
            "Epoch 3/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 606ms/step - accuracy: 0.7847 - loss: 0.5611 - val_accuracy: 0.9062 - val_loss: 0.2697\n",
            "Epoch 4/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 599ms/step - accuracy: 0.7859 - loss: 0.5491 - val_accuracy: 0.8438 - val_loss: 0.3913\n",
            "Epoch 5/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m604s\u001b[0m 599ms/step - accuracy: 0.7971 - loss: 0.5278 - val_accuracy: 0.9375 - val_loss: 0.2154\n",
            "Epoch 6/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 597ms/step - accuracy: 0.7963 - loss: 0.5368 - val_accuracy: 0.8750 - val_loss: 0.2852\n",
            "Epoch 7/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 608ms/step - accuracy: 0.8041 - loss: 0.5105 - val_accuracy: 0.9062 - val_loss: 0.2050\n",
            "Epoch 8/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 592ms/step - accuracy: 0.8083 - loss: 0.5037 - val_accuracy: 0.9062 - val_loss: 0.2034\n",
            "Epoch 9/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 594ms/step - accuracy: 0.8074 - loss: 0.5048 - val_accuracy: 0.8750 - val_loss: 0.2753\n",
            "Epoch 10/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m594s\u001b[0m 591ms/step - accuracy: 0.8098 - loss: 0.5028 - val_accuracy: 0.9375 - val_loss: 0.2193\n",
            "Epoch 11/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 609ms/step - accuracy: 0.8160 - loss: 0.4832 - val_accuracy: 0.9375 - val_loss: 0.2082\n",
            "Epoch 12/12\n",
            "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 629ms/step - accuracy: 0.8139 - loss: 0.4826 - val_accuracy: 0.9375 - val_loss: 0.2131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "\n",
        "def create_densenet():\n",
        "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "    output = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "densenet_model = create_densenet()\n",
        "history_densenet = densenet_model.fit(train_generator, validation_data=val_generator, epochs=12)\n",
        "densenet_model.save('densenet_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have your test_generator defined as before\n",
        "test_loss, test_accuracy = densenet_model.evaluate(test_generator)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKqtwgKN9hR-",
        "outputId": "f6d99f71-dfed-4f96-be75-5535115f40f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 449ms/step - accuracy: 0.9426 - loss: 0.1915\n",
            "Test Loss: 0.1857\n",
            "Test Accuracy: 0.9432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zubW_0JtyP2U"
      },
      "source": [
        "5. Create and Train the Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BwWjewq9yTFP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "9459dcbd-395f-4348-d119-887d6812dcc0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'efficientnet_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-815c2541dba7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load trained models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mefficientnet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'efficientnet_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresnet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdensenet_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'densenet_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    192\u001b[0m         )\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    559\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'efficientnet_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ],
      "source": [
        "# Load trained models\n",
        "efficientnet_model = load_model('fine_tuned_efficientnet.h5')\n",
        "resnet_model = load_model('fine_tuned_resnet.h5')\n",
        "densenet_model = load_model('densenet_model.h5')\n",
        "\n",
        "# Freeze all models\n",
        "for model in [efficientnet_model, resnet_model, densenet_model]:\n",
        "    model.trainable = False\n",
        "\n",
        "# Create ensemble output\n",
        "efficientnet_output = efficientnet_model.output\n",
        "resnet_output = resnet_model.output\n",
        "densenet_output = densenet_model.output\n",
        "\n",
        "ensemble_output = Average()([efficientnet_output, resnet_output, densenet_output])\n",
        "\n",
        "# Create ensemble model\n",
        "ensemble_model = Model(\n",
        "    inputs=[efficientnet_model.input, resnet_model.input, densenet_model.input],\n",
        "    outputs=ensemble_output\n",
        ")\n",
        "\n",
        "ensemble_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the ensemble (optional fine-tuning)\n",
        "history_ensemble = ensemble_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=5\n",
        ")\n",
        "\n",
        "ensemble_model.save('ensemble_model.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuQTnocnyV6L"
      },
      "source": [
        "Evaluate the Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHPw3XZy4fAA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5JLu571yZo-"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = ensemble_model.evaluate(test_generator)\n",
        "print(f\"Ensemble Test Accuracy: {test_accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ5DBXrvxu8q"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1R53UTIiHVB8eS87AMzjdm3zcHzx4B13A",
      "authorship_tag": "ABX9TyMaV+BCAO+ndotvIVRe9Hwd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}